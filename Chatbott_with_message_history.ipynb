{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " #Import and set API keys securely\n",
        "import os"
      ],
      "metadata": {
        "id": "Y2vCGVA2awvw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = userdata.get(\"HUGGINGFACE_API_KEY\")\n"
      ],
      "metadata": {
        "id": "HDguK1qta7fz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "sample_text = \"\"\"\n",
        "LangChain is a framework to build LLM-powered applications using components like memory, chaining, agents, and retrievers.\n",
        "It allows developers to easily integrate large language models with tools, APIs, and memory to build complex reasoning applications.\n",
        "\"\"\"\n",
        "\n",
        "documents = [Document(page_content=sample_text)]\n"
      ],
      "metadata": {
        "id": "rpElDxLpbJ9R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the documnets\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "print(f\" Total Chunks: {len(split_docs)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6uSOyBUcdjE",
        "outputId": "71401f3e-e820-488b-ca48-da5b3d950af5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Total Chunks: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embedding_model = HuggingFaceHubEmbeddings(\n",
        "    repo_id=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    huggingfacehub_api_token=os.environ[\"HUGGINGFACE_API_KEY\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uaIkaBqdctqb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "AqEy4zMRd2Du"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating vector db to store embeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=split_docs,\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=\"./chroma_db1\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "0-fzTGJnftbq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the retriver\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "_kzuF1TEhUzO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model_name=\"gemma2-9b-it\",\n",
        "    temperature=0\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "XqNFAOswhr8u"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding memory for conversation\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "of9-YQt-iabe"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RAG Chain with Conversational Memory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "rag_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "f0HolsqbiqFd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RAG Chatbot Ready! Type 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\" Goodbye!\")\n",
        "        break\n",
        "    response = rag_chain.invoke({\"question\": user_input})\n",
        "    print(\"chatBot:\", response[\"answer\"])\n"
      ],
      "metadata": {
        "id": "tdW8gqgFi8CN",
        "outputId": "0adedce6-65ca-4f34-eef4-b8293f5e3da8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¤– RAG Chatbot Ready! Type 'exit' to stop.\n",
            "\n",
            "You: hey my name is shoeb\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "LangChain is a framework to build LLM-powered applications using components like memory, chaining, agents, and retrievers.\n",
            "It allows developers to easily integrate large language models with tools, APIs, and memory to build complex reasoning applications.\n",
            "Human: hey my name is shoeb\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Hello Shoeb! \n",
            "\n",
            "It's nice to meet you.  \n",
            "\n",
            "What can I do for you today?  \n",
            "\n",
            "\n",
            "You: can you help me\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: hey my name is shoeb\n",
            "Assistant: Hello Shoeb! \n",
            "\n",
            "It's nice to meet you.  \n",
            "\n",
            "What can I do for you today?  \n",
            "\n",
            "\n",
            "Follow Up Input: can you help me\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "LangChain is a framework to build LLM-powered applications using components like memory, chaining, agents, and retrievers.\n",
            "It allows developers to easily integrate large language models with tools, APIs, and memory to build complex reasoning applications.\n",
            "Human: Can you help me? \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Please ask your question! I'm ready to help if I can, using my knowledge of LangChain.  \n",
            "\n",
            "\n",
            "You: who created you\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: hey my name is shoeb\n",
            "Assistant: Hello Shoeb! \n",
            "\n",
            "It's nice to meet you.  \n",
            "\n",
            "What can I do for you today?  \n",
            "\n",
            "\n",
            "Human: can you help me\n",
            "Assistant: Please ask your question! I'm ready to help if I can, using my knowledge of LangChain.  \n",
            "\n",
            "\n",
            "Follow Up Input: who created you\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "LangChain is a framework to build LLM-powered applications using components like memory, chaining, agents, and retrievers.\n",
            "It allows developers to easily integrate large language models with tools, APIs, and memory to build complex reasoning applications.\n",
            "Human: Who created you? \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: I don't know who created LangChain. \n",
            "\n",
            "You: what is the purpose of this chat bott\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: hey my name is shoeb\n",
            "Assistant: Hello Shoeb! \n",
            "\n",
            "It's nice to meet you.  \n",
            "\n",
            "What can I do for you today?  \n",
            "\n",
            "\n",
            "Human: can you help me\n",
            "Assistant: Please ask your question! I'm ready to help if I can, using my knowledge of LangChain.  \n",
            "\n",
            "\n",
            "Human: who created you\n",
            "Assistant: I don't know who created LangChain. \n",
            "\n",
            "Follow Up Input: what is the purpose of this chat bott\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "LangChain is a framework to build LLM-powered applications using components like memory, chaining, agents, and retrievers.\n",
            "It allows developers to easily integrate large language models with tools, APIs, and memory to build complex reasoning applications.\n",
            "Human: What is the purpose of this chatbot? \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Based on the context provided, the purpose of this chatbot is to help users understand what LangChain is and what it can be used for.  \n",
            "\n",
            "You: can you tell me my name\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: hey my name is shoeb\n",
            "Assistant: Hello Shoeb! \n",
            "\n",
            "It's nice to meet you.  \n",
            "\n",
            "What can I do for you today?  \n",
            "\n",
            "\n",
            "Human: can you help me\n",
            "Assistant: Please ask your question! I'm ready to help if I can, using my knowledge of LangChain.  \n",
            "\n",
            "\n",
            "Human: who created you\n",
            "Assistant: I don't know who created LangChain. \n",
            "\n",
            "Human: what is the purpose of this chat bott\n",
            "Assistant: Based on the context provided, the purpose of this chatbot is to help users understand what LangChain is and what it can be used for.  \n",
            "\n",
            "Follow Up Input: can you tell me my name\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "LangChain is a framework to build LLM-powered applications using components like memory, chaining, agents, and retrievers.\n",
            "It allows developers to easily integrate large language models with tools, APIs, and memory to build complex reasoning applications.\n",
            "Human: What is my name? \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: I don't know your name.  \n",
            "\n",
            "You: exit\n",
            "ðŸ‘‹ Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IBBSS03tjJKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}